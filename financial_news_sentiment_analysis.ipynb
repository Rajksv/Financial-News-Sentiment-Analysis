{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RF9ztNQ_HH1S"
   },
   "source": [
    "#Financial News Sentiment Analysis\n",
    "\n",
    "\n",
    "> About the Dataset\n",
    "\n",
    "India financial news sentiment analysis dataset compiled together.\n",
    "\n",
    "Date range: Jan 1, 2017 to April 15, 2021\n",
    "\n",
    "News sources:\n",
    "Indian sources: Economic Times, Money Control, Livemint, Business Today, Financial Express\n",
    "Foreign sources: NY Times, WSJ, Washington Post\n",
    "\n",
    "Keywords:\n",
    "Indian sources: \"economy\" or \"markets\" or \"inflation\"\n",
    "Foreign sources: \"Indian economy\" OR \"India economy\" OR \"Indian businesses\" OR \"Indian business\"\n",
    "\n",
    "Sentiment analysis: Performed using flair NLP model. All confidence scores for NEGATIVE sentiment datapoints have been multiplied by -1 from the original flair output. Basic cleanup of data done to remove repetition of headlines and all headlines less than 30 characters are ignored.\n",
    "\n",
    "Acknowledgements: GDELT Headline Scrape script from Prof. Ken Blake (https://drkblake.com/gdeltheadlinescrape/) has been used to generate the news headlines dataset.\n",
    "\n",
    "Motivation: The intent of generating this data was to compile recent years financial news headlines for India and perform sentiment analysis on it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjz5cRWbG1dX"
   },
   "source": [
    "Connecting Google Colab to Kaggle to get Dataset directly to colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z40L2dMJIKDV"
   },
   "source": [
    "Downloading the helper functions designed by mrdbourke which contains custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14lcGF09ycxN",
    "outputId": "90e302ac-851b-4030-d125-25cb66d9bf1c"
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLQa4EnfIcoZ"
   },
   "source": [
    "Importing required functions from helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "PPGYFIrMyhdW"
   },
   "outputs": [],
   "source": [
    "from helper_functions import unzip_data, plot_loss_curves, make_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHhaRpRiItVb"
   },
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "M695fmj2yxeY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzUslyaWI4y9"
   },
   "source": [
    "#Part 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJxrzwbbJFEP"
   },
   "source": [
    "importing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "y_Xhn09i1x4k"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"News_sentiment_Jan2017_to_Apr2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "p8mdpAH52vOO",
    "outputId": "2c369bd7-2f4a-4420-9dfb-8bf695491435"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Eliminating shadow economy to have positive im...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/econo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.996185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Two Chinese companies hit roadblock with India...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/econo...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>-0.955493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>SoftBank India Vision gets new $100</td>\n",
       "      <td>http://economictimes.indiatimes.com/small-biz/...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.595612</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Nissan halts joint development of luxury cars ...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/inter...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>-0.996672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Despite challenges Rajasthan continues to prog...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/polit...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                              Title  \\\n",
       "0  05/01/17  Eliminating shadow economy to have positive im...   \n",
       "1  05/01/17  Two Chinese companies hit roadblock with India...   \n",
       "2  05/01/17                SoftBank India Vision gets new $100   \n",
       "3  05/01/17  Nissan halts joint development of luxury cars ...   \n",
       "4  05/01/17  Despite challenges Rajasthan continues to prog...   \n",
       "\n",
       "                                                 URL sentiment  confidence  \\\n",
       "0  http://economictimes.indiatimes.com/news/econo...  POSITIVE    0.996185   \n",
       "1  http://economictimes.indiatimes.com/news/econo...  NEGATIVE   -0.955493   \n",
       "2  http://economictimes.indiatimes.com/small-biz/...  POSITIVE    0.595612   \n",
       "3  http://economictimes.indiatimes.com/news/inter...  NEGATIVE   -0.996672   \n",
       "4  http://economictimes.indiatimes.com/news/polit...  POSITIVE    0.997388   \n",
       "\n",
       "   Unnamed: 5  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIH1zFlOJTj_"
   },
   "source": [
    "Label Encoding to sentiment column\n",
    "\n",
    "\n",
    "> Details\n",
    "\n",
    "As we are dealing with binary classification, we need to convert sentiment column class name (\"POSITIVE\", \"NEGATIVE\") to binary(0,1) because we are going to process this data to Neural Network , the class value must be in binary for this problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "OwTPfIzw22rX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['sentiment'] = le.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Fth-JdqV3P40",
    "outputId": "d4df2032-3e3a-4a60-a092-6c54849a08f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Eliminating shadow economy to have positive im...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/econo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Two Chinese companies hit roadblock with India...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/econo...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.955493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>SoftBank India Vision gets new $100</td>\n",
       "      <td>http://economictimes.indiatimes.com/small-biz/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595612</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Nissan halts joint development of luxury cars ...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/inter...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.996672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/01/17</td>\n",
       "      <td>Despite challenges Rajasthan continues to prog...</td>\n",
       "      <td>http://economictimes.indiatimes.com/news/polit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date                                              Title  \\\n",
       "0  05/01/17  Eliminating shadow economy to have positive im...   \n",
       "1  05/01/17  Two Chinese companies hit roadblock with India...   \n",
       "2  05/01/17                SoftBank India Vision gets new $100   \n",
       "3  05/01/17  Nissan halts joint development of luxury cars ...   \n",
       "4  05/01/17  Despite challenges Rajasthan continues to prog...   \n",
       "\n",
       "                                                 URL  sentiment  confidence  \\\n",
       "0  http://economictimes.indiatimes.com/news/econo...          1    0.996185   \n",
       "1  http://economictimes.indiatimes.com/news/econo...          0   -0.955493   \n",
       "2  http://economictimes.indiatimes.com/small-biz/...          1    0.595612   \n",
       "3  http://economictimes.indiatimes.com/news/inter...          0   -0.996672   \n",
       "4  http://economictimes.indiatimes.com/news/polit...          1    0.997388   \n",
       "\n",
       "   Unnamed: 5  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzdHcZ3aLMqQ"
   },
   "source": [
    "Spliting the data into train_sentences, val_sentences, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "WjimSV9u3t35"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(df['Title'].to_numpy(),\n",
    "                                                                            df['sentiment'].to_numpy(),\n",
    "                                                                            test_size = 0.2,\n",
    "                                                                            random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9UPIx2bLWky"
   },
   "source": [
    "Create datasets (as fast as possible)\n",
    "\n",
    "\n",
    "\n",
    "> tf.data: Build TensorFlow input pipelines and better performance with the tf.data API\n",
    "  \n",
    "\n",
    "we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ZkJIEJ7G8A_6"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "kRa7yT738u5R"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUnNiVmfMp05"
   },
   "source": [
    "#Part 2 : Embeding the Inputs (sentences) using Transfer Learning\n",
    "\n",
    "\n",
    "\n",
    "> Converting text into numbers\n",
    "\n",
    "you can build your own tokenizer and embedding layer but for this problem im gonna using  pre-trained word embeddings i.e Universal Sentence Encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELexOyhdOTiz"
   },
   "source": [
    "loading pretrained model from hub to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "38XlQgNi4k9S"
   },
   "outputs": [],
   "source": [
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfqwvk0iOZXl"
   },
   "source": [
    "creating sentence encoder layer which we gonna add in neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "ZrC3uZDj4v8F"
   },
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\", input_shape = [], dtype = \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_zHSSw_OlVn"
   },
   "source": [
    "#Part 3 : Build the Deep Learning Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiIOOVtUOwAA"
   },
   "source": [
    "Building LSTM Model using Functional Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "57otrTCz58va"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = [], dtype = \"string\", name = \"input_layer\")\n",
    "x = sentence_encoder_layer(inputs)\n",
    "x = tf.expand_dims(x, axis = 1)\n",
    "x = layers.Bidirectional(layers.LSTM(72, return_sequences = True))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(72, return_sequences = True))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(72))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation = 'sigmoid', name = 'output_layer')(x)\n",
    "model = tf.keras.Model(inputs, outputs, name = \"model_lstm\")\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10970432882806203582\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lq6A-raPKhf"
   },
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x23BVYmg7bll",
    "outputId": "efaaab84-7e66-4ea7-b5d6-8e1634deee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5013/5013 [==============================] - 1086s 206ms/step - loss: 0.4938 - accuracy: 0.7601 - val_loss: 0.4691 - val_accuracy: 0.7740\n",
      "Epoch 2/10\n",
      "5013/5013 [==============================] - 1018s 203ms/step - loss: 0.4718 - accuracy: 0.7737 - val_loss: 0.4594 - val_accuracy: 0.7809\n",
      "Epoch 3/10\n",
      "4408/5013 [=========================>....] - ETA: 1:38 - loss: 0.4628 - accuracy: 0.7786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data = valid_dataset, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lq9HPUTPQuW"
   },
   "source": [
    "ploting the loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "rmyKmJABAJ24",
    "outputId": "3eac8fc7-169d-48d8-9f6d-c0bbcac9f6d0"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utVMQsQUPV7w"
   },
   "source": [
    "#Part 4 : Evaluating the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOES1ympPr5E"
   },
   "source": [
    "Testing Model on Validation sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0LwjwVJC5-2",
    "outputId": "0c5b5c45-efbf-4fa7-8efa-41cfe315c82c"
   },
   "outputs": [],
   "source": [
    "y_probs = model.predict(val_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U69-IYQ7P86H"
   },
   "source": [
    "converting the probabilities  in y_probs variables to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Nktk3_PZPx39"
   },
   "outputs": [],
   "source": [
    "y_preds = tf.round(y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4r1xJVQQG-x"
   },
   "source": [
    "Comparing the results with actual validation labels with model predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ech5x8hzDRTa",
    "outputId": "d71eb535-3681-498e-b7a9-7a4499d13d6c"
   },
   "outputs": [],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwFRQS74DTrS",
    "outputId": "936617ce-05ee-4ffa-b382-f604d9ab95bf"
   },
   "outputs": [],
   "source": [
    "val_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRUknCd7QTG7"
   },
   "source": [
    "Building the Confustion Matrix to check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "ZIDU6VswDlX-",
    "outputId": "9d48cb6b-4219-4130-a513-f60140fb03b1"
   },
   "outputs": [],
   "source": [
    "make_confusion_matrix(val_labels, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wesRXLydQgEt"
   },
   "source": [
    "Saving the model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "JDuCL1YWIZnU"
   },
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQeGbGfUQoFZ"
   },
   "source": [
    "loading the model to ceck whether all weights are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Y9fd-UjsIHR6"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"best_model.h5\",custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "6pRODldTR_SW"
   },
   "outputs": [],
   "source": [
    "model.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owboakteQvZZ"
   },
   "source": [
    "#Part 5 : Realtime Testing of the Trained Model before Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeDTbZUpRNyO"
   },
   "source": [
    "sentence from Economics Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "uwyrKEXmdgp-"
   },
   "outputs": [],
   "source": [
    "custom = \"Student loan forgiveness has scammers ‘on the move,’ warns FTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = \"Sobana is annoying\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxt09v4cRqHU"
   },
   "source": [
    "creating a function to predict whether its is postive or negative news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "-DwxUw33-tHw"
   },
   "outputs": [],
   "source": [
    "def predict_on_sentence(model, sentence):\n",
    "  \"\"\"\n",
    "  Uses model to make a prediction on sentence.\n",
    "\n",
    "  Returns the sentence, the predicted label and the prediction probability.\n",
    "  \"\"\"\n",
    "  pred_prob = model.predict([sentence])\n",
    "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
    "  print(f\"Pred: {pred_label}\", \"(It's a Positive News)\" if pred_label > 0 else \"(It's a Negative News)\", f\"Prob: {pred_prob[0][0]}\")\n",
    "  print(f\"Text:\\n{sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHeWWqLeR3T2"
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLt_5C8B_1Ek",
    "outputId": "7296e429-2edc-4ee7-e8f0-f2976ab1fdf7"
   },
   "outputs": [],
   "source": [
    "predict_on_sentence(model = model, sentence=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
